<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.40.2" />
  <meta name="author" content="Balakumar Sundaralingam">
  <meta name="description" content="PhD Student, Utah Robotics Center">

  
  <link rel="alternate" hreflang="en-us" href="/class_proj/optic_flow/">

  
  


  

  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Balakumar Sundaralingam">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Balakumar Sundaralingam">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/class_proj/optic_flow/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Balakumar Sundaralingam">
  <meta property="og:url" content="/class_proj/optic_flow/">
  <meta property="og:title" content="Optic Flow based  Collision Avoidance for holonomic mobile robots | Balakumar Sundaralingam">
  <meta property="og:description" content=""><meta property="og:image" content="/img/headers/optic_flow.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2015-05-01T00:00:00-06:00">
  
  <meta property="article:modified_time" content="2015-05-01T00:00:00-06:00">
  

  

  <title>Optic Flow based  Collision Avoidance for holonomic mobile robots | Balakumar Sundaralingam</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Balakumar Sundaralingam</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        

        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Research</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#class_proj">
            
            <span>Course Projects</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Blog</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  
<div class="article-header">
  <img src="/img/headers/optic_flow.png" class="article-banner" itemprop="image">
  <span class="article-header-caption">The red cross on the left image shows the pixel is close to the camera. The robot uses this to move to the left as seen in the right image.</span>
</div>



  <div class="article-container">
    <div class="article-inner">
      <h1 itemprop="name">Optic Flow based  Collision Avoidance for holonomic mobile robots</h1>

      

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2015-05-01 00:00:00 -0600 MDT" itemprop="datePublished">
      May 1, 2015
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    6 min read
  </span>
  

  
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Optic%20Flow%20based%20%20Collision%20Avoidance%20for%20holonomic%20mobile%20robots&amp;url=%2fclass_proj%2foptic_flow%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fclass_proj%2foptic_flow%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fclass_proj%2foptic_flow%2f&amp;title=Optic%20Flow%20based%20%20Collision%20Avoidance%20for%20holonomic%20mobile%20robots"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fclass_proj%2foptic_flow%2f&amp;title=Optic%20Flow%20based%20%20Collision%20Avoidance%20for%20holonomic%20mobile%20robots"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Optic%20Flow%20based%20%20Collision%20Avoidance%20for%20holonomic%20mobile%20robots&amp;body=%2fclass_proj%2foptic_flow%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


      <div class="article-style" itemprop="articleBody">
        

<h4 id="contributors">Contributors:</h4>

<p>Balakumar Sundaralingam.</p>

<h1 id="introduction">Introduction</h1>

<p>Optical flow is one of the many ways to detect motion in a video stream.
Conversely it can be used to interact with the real 3d world. Exploring
this possibility motivated me to see if optical flow from a single
camera is good for collision avoidance. The base idea is to have the
environment static and the camera moving. This is discussed in the below
sections.</p>

<h1 id="problem-statement">Problem Statement</h1>

<p>An holonomic ground robot which is equipped with a single camera facing
in the forward direction should go forward and in the presence of
obstacles, the robot should avoid collisions and continue forward. The
collision avoidance must be done only using the on-board camera. The
following assumptions are made pertaining to the problem:</p>

<ol>
<li><p>The environment is fairly simple mainly made of
non-textured surfaces.</p></li>

<li><p>The obstacles in the environment are highly textured.</p></li>

<li><p>The environment is static and the robot is the only moving object.</p></li>
</ol>

<h1 id="approach">Approach</h1>

<p>To avoid obstacles with only one camera, many methods are present but to
keep it related to the topics taught in class, Optical flow is chosen.
Optical flow is detects the direction of motion in a set of images. This
is the case if the camera is static and there are dynamic objects in the
scene. Conversely if the camera is dynamic and the environment is
static, there will be flow vectors throughout the scene. Now in this
case, we know that objects close to the camera will have a larger flow
vector compared to objects far away. This can be seen in
fig.1. This property is used to avoid obstacles.</p>

<figure>
<img src="/img/course_proj/cv_optic_flow.gif" style="height:200px;">
<figcaption>The test here uses the optical flow method taught in class lectures
and is a version of Lucas Kanade method of optical flow. The red points
are flow vectors having magnitude greater than a threshold.</a></figcaption>
</figure>

<p>The optical flow approach used here is similar to Project 4. The
difference being in computing only for pixels which are detected as
features. Initially, I used the basic approach taught in project 4, but
it was very slow as optical flow was being computed for every pixel. To
make it real-time, the code should run at least at 20Hz. Optical flow
will be faster if it is only used on extracted features. To do this, I
had to implement a feature extraction algorithm. Due to lack of
knowledge in feature extraction, I used an OpenCV function called
“goodFeaturesToTrack” to detect features. Once the features were
detected, the following equations are used:
$$x_{derivative}=\frac{image_{1}(i-1,j)-image_{1}(i+1,j)}{2}$$
$$y_{derivative}=\frac{image_{1}(i,j-1)-image_{1}(i,j+1)}{2}$$
$$time_{derivative}=image_{1}(i,j)-image_{2}(i,j)$$ where $image_{1}$
and $image_{2}$ are gaussian smoothed consequent frames.i,j are row and
column position of the pixels. The above values are used to compute the
flow vector using the below formula: $$v=-(A^{T}A)^{-1}A^{T}b$$ where A
is a Nx2 matrix with columns as x and y derivatives of the chosen window
size(NxN).b is a Nx1 matrix of time derivatives of the chosen window
size.v is a 2x1 matrix having velocity components along x and y
directions.</p>

<p>With the approach for computing optic flow in a set of images explained,
the next step is to use this method to do collision avoidance.
<figure>
<img src="/img/course_proj/cv_chart.png" style="height:200px;">
<figcaption>The input from camera is split into left and right halves. Optical
flow is used to compute the maximum vectors from each side and sent to a
control algorithm which decides the robot motion based on the maximum
vectors.</a></figcaption>
</figure></p>

<p>The maximum vectors from left and right halves are checked with a
threshold vector to check if any obstacle is close to the robot and if
the robot is on a collision course. The robot motion is chosen by the
logic seen in the below table. So the robot is in constant motion
as it avoids obstacles. When both halves have velocity vectors greater
than the threshold, the robot will halt, but when it halts, the vectors
become zero and hence the robot keeps oscillating.</p>

<p><table>
<caption>Robot direction table</caption>
<thead>
<tr class="header">
<th align="left"><strong>Greater Than Threshold vector</strong></th>
<th align="left"><strong>Robot direction of motion</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">None</td>
<td align="left">Forward</td>
</tr>
<tr class="even">
<td align="left">Left half Maximum vector</td>
<td align="left">Go right</td>
</tr>
<tr class="odd">
<td align="left">Right half Maximum vector</td>
<td align="left">Go Left</td>
</tr>
<tr class="even">
<td align="left">Both halves’ Maximum vectors</td>
<td align="left">Stop</td>
</tr>
</tbody>
</table></p>

<h1 id="implementation">Implementation</h1>

<p>The robot has to perform computations in real-time and hence OpenCV
libraries are used. To compute matrices for optical flow, the eigen
library is used. The processing is all done on-board the robot in a ARM
based single board computer called ODROID-U3. It runs a custom version
of linux. The Robotics Operating System (ROS) is used as the
framework for easy implementation. With all the optimizations done to
the best of my knowledge, the optical flow algorithm ran at 50Hz.</p>

<figure>
<img src="/img/course_proj/cv_robot.png" style="height:200px;">
<figcaption>The robot is equipped with a RGB color camera, on-board computer
which takes the camera input and does optic flow and controls the
motors. The mecannum wheels allow the robot to have holonomic
capabilities and so the robot can move sideways.</a></figcaption>
</figure>

<h1 id="results-and-discussion">Results and Discussion</h1>

<p>The approach is tested in a long corridor with minimum textures.The
robot was run in two different setups. The first run is in the presence of two obstacles and the robot
moves left and right to avoid collision as seen below:
<figure>
<img src="/img/course_proj/cv_res_1.png" style="height:200px;">
<figcaption> The robot sees optic flow greater than the threshold in the right
half of the camera as seen by blue vectors in the right half and so the
robot moves to the left as shown by the red vector.</a></figcaption>
</figure></p>

<figure>
<img src="/img/course_proj/cv_res_2.png" style="height:200px;">
<figcaption>The robot sees optic flow greater than the threshold in the left half
of the camera as seen by blue vectors in the left half and so the robot
moves to the right as shown by the red vector.</a></figcaption>
</figure>
 The next run is in the presence of an obstacle which is in both halves. This case would make the robot halt and oscillate as optic flow is computed only when the robot is in motion as seen below.
<figure>
<img src="/img/course_proj/cv_res_3.png" style="height:200px;">
<figcaption> The robot sees optic flow greater than the threshold in both the
right half and left half of the camera as seen by blue vectors and so
the robot stays in place but when is static, the flow vectors disappear
and hence the robot oscillates, this can be seen in the submitted
video.</a></figcaption>
</figure>

<h1 id="code-and-video">Code and Video</h1>

<p>The code is done in C++ with eigen and OpenCV libraries. The following
inbuilt functions from OpenCV are used: goodFeaturesToTrack(to find
features) and GaussianBlur (to blur the image for optical flow
computation). No functions from OpenCV for Optical flow was used. The
Optical flow code was done manually. The code compiles in Linux and
requires ROS hydro or newer frameworks to work.</p>

<h5 id="source-code-git-https-github-com-balakumar-s-opticflow-collision-avoidance-git">Source Code:<a href="https://github.com/balakumar-s/opticflow_collision_avoidance.git" target="_blank">Git</a></h5>

<p>In the video below, the stream from the on-board camera is lagging due to low
bandwidth of the wireless network and is not related to the algorithm.

<div style="position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/MvWAp7sOZlA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" allowfullscreen frameborder="0" title="YouTube Video"></iframe>
 </div>
</p>

<h1 id="conclusion">Conclusion</h1>

<p>Thus it is seen that optical flow can be used to do collision avoidance
if there is enough texture in the obstacles. This can be expanded to use
with cheap collision avoidance systems such as in toys.</p>

      </div>

      


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/collision-avoidance">collision-avoidance</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/mobile-robot">mobile-robot</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/motion-planning">motion-planning</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/ros">ROS</a>
  
</div>



    </div>
  </div>

</article>



<div class="article-container article-widget">
  <div class="hr-light"></div>
  <h3>Related</h3>
  <ul>
    
    <li><a href="/class_proj/collision_avoidance/">Artificial Potential Field Collision Avoidance for holonomic mobile robots</a></li>
    
    <li><a href="/post/mobile_robot_simulation/">Mobile robot simulation in Gazebo</a></li>
    
    <li><a href="/project/mobile_robot_mapping/"> Mapping using only laser range finder on Mobile Robot</a></li>
    
  </ul>
</div>



<div class="container article-widget">
  <nav>
  <ul class="pager">
    

    
    <li class="next"><a href="/class_proj/collision_avoidance/">Artificial Potential Field Collision Avoidance for holonomic mobile robots <span
      aria-hidden="true">&rarr;</span></a></li>
    
  </ul>
</nav>

</div>


<div class="article-container">
  

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2018 Balakumar Sundaralingam &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

