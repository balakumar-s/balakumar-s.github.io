<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mobile-robot on Balakumar Sundaralingam</title>
    <link>/tags/mobile-robot/</link>
    <description>Recent content in Mobile-robot on Balakumar Sundaralingam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Balakumar Sundaralingam</copyright>
    <lastBuildDate>Fri, 01 May 2015 00:00:00 -0700</lastBuildDate>
    
	<atom:link href="/tags/mobile-robot/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Artificial Potential Field Collision Avoidance for holonomic mobile robots</title>
      <link>/class_proj/collision_avoidance/</link>
      <pubDate>Fri, 01 May 2015 00:00:00 -0700</pubDate>
      
      <guid>/class_proj/collision_avoidance/</guid>
      <description>Contributors: Balakumar Sundaralingam, Rohith Prasad.
Introduction The use of tele-operated robots in search and rescue, environment monitoring and interstellar exploration has increased in the past years. Tele-operation of robots is a complex task. The operator not only has to focus on the task but also perform collision avoidance so that the robot does not collide with obstacles in the environment. The addition of an automatic collision avoidance system to the robot will ease the operator and allow the operator to focus more on the task.</description>
    </item>
    
    <item>
      <title>Optic Flow based  Collision Avoidance for holonomic mobile robots</title>
      <link>/class_proj/optic_flow/</link>
      <pubDate>Fri, 01 May 2015 00:00:00 -0700</pubDate>
      
      <guid>/class_proj/optic_flow/</guid>
      <description>Contributors: Balakumar Sundaralingam.
Introduction Optical flow is one of the many ways to detect motion in a video stream. Conversely it can be used to interact with the real 3d world. Exploring this possibility motivated me to see if optical flow from a single camera is good for collision avoidance. The base idea is to have the environment static and the camera moving. This is discussed in the below sections.</description>
    </item>
    
    <item>
      <title>Mobile robot simulation in Gazebo</title>
      <link>/post/mobile_robot_simulation/</link>
      <pubDate>Sun, 01 Jun 2014 00:00:00 -0700</pubDate>
      
      <guid>/post/mobile_robot_simulation/</guid>
      <description>To get to speed with ROS and Gazebo, I created the Pioneer 3AT robot from mesh files. Learning about simulating the robot&amp;rsquo;s drive motors was interesting. This code is available in git. Here is a video of the simulation.   Out of curiosity, I also setup hector slam to generate a map of the environment.   </description>
    </item>
    
    <item>
      <title> Mapping using only laser range finder on Mobile Robot</title>
      <link>/project/mobile_robot_mapping/</link>
      <pubDate>Sat, 27 Apr 2013 00:00:00 +0000</pubDate>
      
      <guid>/project/mobile_robot_mapping/</guid>
      <description>Contributors: Balakumar Sundaralingam, Sudarsan Balaji, Yaswanth Kodavali.
Advisor: Prof. Prem S. Abstract Mobile robots employ wheel encoders to generate odometric readings. But the odometric readings from the wheel encoders of the mobile robots are generally erroneous, even in indoor environments. Without proper guiding tools like GPS, it is very hard to localise the robot in each consecutive scan for mapping. To overcome this disadvantage, a generic approach to formulate an error function using wheel encoder readings is followed.</description>
    </item>
    
  </channel>
</rss>