<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.53" />
  <meta name="author" content="Balakumar Sundaralingam">
  <meta name="description" content="PhD Candidate">

  
  <link rel="alternate" hreflang="en-us" href="/post/ml_proj/">

  
  


  

  
  
  
  
    
  
  
    
    
      
        <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
      
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7cMerriweather%7cRoboto&#43;Mono%7cLibre&#43;Baskerville%7cMontserrat">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Balakumar Sundaralingam">
  <link rel="feed" href="/index.xml" type="application/rss+xml" title="Balakumar Sundaralingam">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/ml_proj/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Balakumar Sundaralingam">
  <meta property="og:url" content="/post/ml_proj/">
  <meta property="og:title" content="Using Push locations to Classify and predict Object Dynamics | Balakumar Sundaralingam">
  <meta property="og:description" content=""><meta property="og:image" content="/img/headers/ml_proj.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2016-12-01T00:00:00-07:00">
  
  <meta property="article:modified_time" content="2016-12-01T00:00:00-07:00">
  

  

  <title>Using Push locations to Classify and predict Object Dynamics | Balakumar Sundaralingam</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Balakumar Sundaralingam</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        

        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Research</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        

        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Blog</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  
<div class="article-header">
  <img src="/img/headers/ml_proj.png" class="article-banner" itemprop="image">
  <span class="article-header-caption">The motion classification based on contact on object is shown</span>
</div>



  <div class="article-container">
    <div class="article-inner">
      <h1 itemprop="name">Using Push locations to Classify and predict Object Dynamics</h1>

      

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2016-12-01 00:00:00 -0700 MST" itemprop="datePublished">
      Dec 1, 2016
    </time>
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    9 min read
  </span>
  

  
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Using%20Push%20locations%20to%20Classify%20and%20predict%20Object%20Dynamics&amp;url=%2fpost%2fml_proj%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=%2fpost%2fml_proj%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fpost%2fml_proj%2f&amp;title=Using%20Push%20locations%20to%20Classify%20and%20predict%20Object%20Dynamics"
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=%2fpost%2fml_proj%2f&amp;title=Using%20Push%20locations%20to%20Classify%20and%20predict%20Object%20Dynamics"
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Using%20Push%20locations%20to%20Classify%20and%20predict%20Object%20Dynamics&amp;body=%2fpost%2fml_proj%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


      <div class="article-style" itemprop="articleBody">
        

<h4 id="contributors">Contributors:</h4>

<p>Balakumar Sundaralingam, Vairavan Sivaraman.</p>

<h1 id="introduction-motivation">Introduction &amp; Motivation</h1>

<p>Predicting an object’s next state without explicitly knowing the
dynamics of the object is an interesting problem which would reduce the
need for building a physical model of an object. This is even more
important in the open world where an object’s dynamics is too complex to
mathematically model. Instead of depending on mathematical models, the
easier way would be to interact with the object at different contact
points and build a classifier to predict the object’s next state. This
idea is explored in this paper with experiments to analyze the
feasibility.</p>

<p>Non-prehensile manipulation also called as graspless manipulation takes
advantage of the mechanics of the task to achieve a goal state without
grasping, thus simple mechanisms are used to achieve complex tasks.
Pushing as shown is a non-prehensile
manipulation primitive, where a point or a line contact pushes an object
against the friction between the table and object surface. Tumbling is a
pushing method in which the object is rotated about an axis around a
plane. Pivoting is a method which requires a minimum of two contact points for effective execution. These
are some motion primitives in the world of robot object
interaction/manipulation of which pushing will be explored to classify
the object motions.
<figure>
  <img src="/img/course_proj/ml_push.png" style="height:200px;">
  <figcaption>Robot Object interaction in its simplest form is a point contact from the robot pushing the object to a goal state by predicting the motion for a contact point</a></figcaption>
</figure></p>

<h1 id="approach">Approach</h1>

<p>The problem statement here is to predict the labels move and rotate,
given a dataset of interactions with the object.</p>

<h2 id="assumptions">Assumptions</h2>

<p>The following assumptions are made about the problem.</p>

<ol>
<li><p>The object is rigid.</p></li>

<li><p>The object has only two motion primitives- move and rotate. And it
cannot have both the motions at the same time.</p></li>

<li><p>The contact point force is constant and acts normal to surface of
the object.</p></li>

<li><p>The Object has uniform density,</p></li>

<li><p>The table surface has an uniform friction coefficient.</p></li>
</ol>

<figure>
  <img src="/img/course_proj/ml_object_class.png" style="height:200px;">
  <figcaption>The object with different motions based on contact point on the surface. Only one half face of the object is shown.</a></figcaption>
</figure>

<h2 id="initial-conception">Initial Conception</h2>

<p>Initially, we attempted to classify a continuous system as in classify
if the object is</p>

<ol>
<li><p>Moving only(Contact is at the centre of the object.)</p></li>

<li><p>Rotating only(Contact is at the edge of the object.)</p></li>

<li><p>Moving and Rotating.(Contact is anywhere between the centre and edge
of the object.)</p></li>
</ol>

<table>
<caption>Accuracy of Prediction for coupled motions.<span label="table:both"></span></caption>
<tbody>
<tr class="odd">
<th align="center" >Feature Space</th>
<th align="center" colspan="2">Move & Rotate Label Accuracy</th>
</tr>
<tr class="even">
<th align="center"></th>
<th align="center">K-NN(K=9)</th>
<th align="center">A-M-Perceptron</th>
</tr>
<tr class="odd">
<th align="center">Contact Point</th>
<td >38.3%</td>
<td >36.5%</td>
</tr>
<tr class="even">
<th align="center">Contact point &amp; Object Pose</th>
<td  >48.5%</td>
<td >35.71%</td>
</tr>
</tbody>
</table>

<p>and the predictions for moving and rotating condition were bad as seen
in Tab. [table:both] and this was reasoned to be because of learning
the weight vector for moving and rotating independently and hence the
lack of coupling between the two labels during the learning phase
arises. So we focused the project on learning a classifier for moving
and rotating independently and removed the motion which had both moving
and rotating. The problem is even simpler now.</p>

<h2 id="problem-statement">Problem Statement</h2>

<p>Given a dataset $S$ which has the following elements:$x,y,z$ -contact location of the point contact on the object,$\dot{X},\dot{Y},\dot{Z}$ - linear velocities of the object on perturbation, $\dot{\theta}_X$, $\dot{\theta}_Y$, $\dot{\theta}_Z$- angular velocity of the object on perturbation and labels Move,Rotate. This dataset is split in the ratio 8:2 and stored in S<sub>train</sub> and S<sub>test</sub> respectively. S<sub>train</sub>  is the training data on which a classifier will be learnt and the prediction accuracy will be checked with S<sub>test</sub>. The goal is to obtain a good classifier for the object.</p>

<h2 id="algorithms-classifiers">Algorithms/ Classifiers</h2>

<p>This problem is a multi label classifier and one way to learn a
classifier is to learn the two labels separately and at prediction time,
use the two learnt methods to predict each label and count success only
when both the labels are predicted correctly. Two classifiers-
Perceptron and Support Vector Machines are implemented to learn the
motions. The aggressive margin version of the Perceptron classifier is
used.</p>

<h1 id="dataset">Dataset</h1>

<h2 id="data-collection">Data Collection</h2>

<p>Data was generated from experiments due to unavailability of previous
data. The experiment consist of pushing an object(a cuboid) with a
marker and recording the change in pose of the object and also the
contact point of the marker on the object. The pose of the object and
marker is recorded as a time series(useful for velocity calculations).
The Kinect sensor is used as the sensor for collecting the pose data.
The marker pose is tracked by using simple blob tracking from OpenCV and
getting the depth using the pointcloud obtained from Kinect. Tracking
the object is complex and thus BLORT tracker. ROS was used as the framework for running the data
collection code. The setup is shown below</p>

<figure>
  <img src="/img/course_proj/ml_data_collection.png" style="height:200px;">
  <figcaption>The left image is a 2-d color image which is used by the Blort tracker to track the object and the marker is tracked using the right image which is a 3-D pointcloud. The three axes x,y and z are represesnted by blue,red and green lines respectively.</a></figcaption>
</figure>

<h2 id="data-processing">Data Processing</h2>

<p>The training data needed to be labeled and two labels- Move and Rotate
were used. Consider an symmetrical object such as a Cuboid. The object
will only rotate when the object is pushed from the edge. The object
will only move(translate) when the object is pushed at the center. We
only assume that there is only two motions available to the object. The
data set is manually labeled. The feature space is taken as the contact
location(x,y,z) and also the object’s
velocity($\dot{X},\dot{Y},\dot{Z}$,$\dot{\theta}_X,\dot{\theta}_Y,\dot{\theta}_Z$).
2000 samples were taken in the dataset, of which 1600 are randomly taken
as the training set and the remaining is the test set.</p>

<h2 id="data-validation">Data Validation</h2>

<p>As the data had to manually labeled, the experiments are run separately
by first only having the contact point on the center and recording the
move-only data and then experiments for rotate-only is performed by
having the contact point on the edge.</p>

<h1 id="feature-space-f-s">Feature Space(F-S)</h1>

<p>The basic features from data collection was insufficient to learn a good classifier. So
to try to improve the accuracy and also to explore how the feature space
affects the classification/Prediction accuracy, a number of feature
transformations are applied to the dataset. The feature transformations
are only done with object data and the contact point data is not
modified. The transformations on the object data are based on different
norms. A p-norm is calculated as follows:
$$ ||\mathbf{x}||_p := \bigg( \sum_{i=1}^n \left| x_i \right| ^p \bigg) ^{1/p} $$
where $x$ is a vector having n components. It can be seen from
Eq. [eq:norm] that when p becomes $\infty$, the norm is the largest
component of the vector. The object has two velocities-linear($l$) and
angular($\omega$) and hence two norms are calculated for the object
velocities. The norms are</p>

<ol>
<li><p>1-norm of the object velocities($N_1^l$,$N_1^\omega$).</p></li>

<li><p>2-norm of the object velocities($N_2^l$,$N_2^\omega$).</p></li>

<li><p>$\infty$-norm of the object
velocities($N^l_\infty$, $N_\infty^\omega$).</p></li>
</ol>

<p>With these norms calculated, the feature spaces tested are expanded as
follows:</p>

<ol>
<li><p>$x,y,z,\dot{X},\dot{Y},\dot{Z},\dot{\theta}_X,\dot{\theta}_Y,\dot{\theta}_Z$</p></li>

<li><p>$\dot{X},\dot{Y},\dot{Z},\dot{\theta}_X,\dot{\theta}_Y,\dot{\theta}_Z$</p></li>

<li><p>$x,y,z,N_1^l,N_1^\omega$</p></li>

<li><p>$N_1^l,N_1^\omega$</p></li>

<li><p>$x,y,z,N_2^l,N_2^\omega$</p></li>

<li><p>$N_2^l,N_2^\omega$</p></li>

<li><p>$x,y,z,N_\infty^l,N_\infty^\omega$</p></li>

<li><p>${N_\infty}^l$,$N_\infty^\omega$</p></li>

<li><p>$x,y,z$</p></li>
</ol>

<p>With these 9 different feature spaces, the accuracies for each
classifier is reported and the results are analyzed in the next section.</p>

<h1 id="results">Results</h1>

<p>The hyper parameters for aggressive margin perceptron(AMP) were
calculated by 10 fold cross validation to be $\mu=1$ and similarly for
support vector machine(SVM) to be $\rho=1,C=10$. The epoch length was
chosen as 100. The result for all the different feature spaces are given
in a table below, in which F-S numbers relate to the numbered
feature spaces. It is clear that the highest
accuracy is shown by svm for F-S 2 which does not have the contact point
location as a feature.</p>

<table>
<caption>Predictions<span label="tab:pred"></span></caption>
<tbody>
<tr class="odd">
<th style="text-align: center;"> F-S</th>
<th style="text-align: center;" colspan="2">Margin-Rotate</th>
<th style="text-align: center;" colspan="2">Margin-Move</th>
<th style="text-align: center;" colspan="2">Accuracy%</th>
</tr>
<tr class="even">
<th style="text-align: center;"></th>
<th style="text-align: center;">AMP</th>
<th style="text-align: center;">SVM</th>
<th style="text-align: center;">AMP</th>
<th style="text-align: center;">SVM</th>
<th style="text-align: center;">AMP</th>
<th style="text-align: center;">SVM</th>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">7.025e-5</td>
<td style="text-align: center;">0.0036</td>
<td style="text-align: center;">6.99e-5</td>
<td style="text-align: center;">0.0037</td>
<td style="text-align: center;">46.84</td>
<td style="text-align: center;">51.39</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">1.34e-6</td>
<td style="text-align: center;">3.82e-8</td>
<td style="text-align: center;">1.31e-6</td>
<td style="text-align: center;">3.99e-7</td>
<td style="text-align: center;">60.7</td>
<td style="text-align: center;">65.37</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">8.43e-05</td>
<td style="text-align: center;">0.0037</td>
<td style="text-align: center;">8.40e-5</td>
<td style="text-align: center;">0.0036</td>
<td style="text-align: center;">40.5</td>
<td style="text-align: center;">51.39</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">0.00065</td>
<td style="text-align: center;">2.89e-5</td>
<td style="text-align: center;">0.00065</td>
<td style="text-align: center;">2.89e-5</td>
<td style="text-align: center;">37.13</td>
<td style="text-align: center;">51.39</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">5.35e-6</td>
<td style="text-align: center;">0.0037</td>
<td style="text-align: center;">6.1e-6</td>
<td style="text-align: center;">0.0037</td>
<td style="text-align: center;">37.75</td>
<td style="text-align: center;">51.39</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">1.74e-7</td>
<td style="text-align: center;">1.86e-5</td>
<td style="text-align: center;">1.74e-7</td>
<td style="text-align: center;">1.86e-5</td>
<td style="text-align: center;">37.13</td>
<td style="text-align: center;">51.39</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">1.012e-5</td>
<td style="text-align: center;">0.0037</td>
<td style="text-align: center;">1.01e-5</td>
<td style="text-align: center;">0.0037</td>
<td style="text-align: center;">38.67</td>
<td style="text-align: center;">51.39</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">6.55e-6</td>
<td style="text-align: center;">1.63e-5</td>
<td style="text-align: center;">6.60e-6</td>
<td style="text-align: center;">1.63e-5</td>
<td style="text-align: center;">37.13</td>
<td style="text-align: center;">51.39</td>
</tr>
<tr class="odd">
<td style="text-align: center;">9</td>
<td style="text-align: center;">1.91e-6</td>
<td style="text-align: center;">0.0037</td>
<td style="text-align: center;">1.91e-6</td>
<td style="text-align: center;">0.0037</td>
<td style="text-align: center;">43.6</td>
<td style="text-align: center;">51.39</td>
</tr>
</tbody>
</table>

<h2 id="effect-of-contact-point">Effect of Contact point</h2>

<p>The contact point has a negative impact in the results as seen in F-S 2
where the contact point location is not considered and it the best
possible accuracy in this project. While in rest of the feature spaces,
the contact point is not having a considerable impact. When only the
contact points were considered as in F-S 9, it resulted in a low
accuracy.</p>

<h2 id="analyzing-the-weight-vectors">Analyzing the weight vectors</h2>

<p>Separate weight vectors were calculated for move and rotate, the
magnitude of all the corresponding elements in both vectors were same
but the sign of each corresponding element were opposite. So as an
experiment, at the prediction state, only either one of the weights was
tested and the accuracy resulted in the same as accounting for both the
weights. This proves the case that the learning either of the motions is
an inverse of the other as we did not account for both the motions
combined.</p>

<h2 id="inference-on-failures">Inference on failures</h2>

<p>Classifying a linear dataset seems an easy classifying problem while
these experiments prove otherwise. A number of factors could be the
reason of which some prominent ones are listed.</p>

<ol>
<li><p>The motions of the object is not purely linear- when the object is
perturbed there will be vibrations due to the impulse force which
will be recorded by the tracker and it might be very high compared
to the normal motion.</p></li>

<li><p>The object motion might also be not purely rotating or purely moving
at any instant and there might be noise.</p></li>

<li><p>The dataset might not be sufficient.</p></li>

<li><p>The force applied on the object may not be a contact force as the
object was perturbed by a human and using a robot manipulator might
produce better results.</p></li>
</ol>

<h1 id="conclusion-future-work">Conclusion &amp; Future Work</h1>

<p>Although the problem is linearly classifiable, the learning algorithms
are not able to learn it. Future work will be on expanding the feature
space to forces and also look into using the pointcloud data without any
tracking which would add a lot of dimensions to the problem and might
also give a solution for coupling multiple motions such as move and
rotate at the same time. Also including different motion primitives such
as sliding, toppling and check if the states can be classified is an
interesting future direction. Also of interest is including the velocity
of the point contact and also the angle at which the contact hits the
object, as the contact angle will cause an object to behave differently
and it might also be non-linear. For a 2000 dataset, the accuracy of
65.37% is a sufficient result.</p>

      </div>

      


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/machine-learning">machine-learning</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/ros">ROS</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/opencv">openCV</a>
  
</div>



    </div>
  </div>

</article>



<div class="article-container article-widget">
  <div class="hr-light"></div>
  <h3>Related</h3>
  <ul>
    
    <li><a href="/post/optic_flow/">Optic Flow based  Collision Avoidance for holonomic mobile robots</a></li>
    
    <li><a href="/post/collision_avoidance/">Artificial Potential Field Collision Avoidance for holonomic mobile robots</a></li>
    
    <li><a href="/post/mobile_robot_simulation/">Mobile robot simulation in Gazebo</a></li>
    
  </ul>
</div>



<div class="container article-widget">
  <nav>
  <ul class="pager">
    
    <li class="previous"><a href="/post/collision_avoidance/"><span
      aria-hidden="true">&larr;</span> Artificial Potential Field Collision Avoidance for holonomic mobile robots</a></li>
    

    
  </ul>
</nav>

</div>


<div class="article-container">
  

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2019 Balakumar Sundaralingam &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

